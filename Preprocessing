import os
import re
import unicodedata
from docx import Document


contractions_fr = {
    r"\bj'ai\b": "je ai",
    r"\bt'as\b": "tu as",
    r"\bc'est\b": "ce est",
    r"\bc'√©tait\b": "ce √©tait",
    r"\bcelle-l√†\b": "celle la",
    r"\bcelles-l√†\b": "celles la",
    r"\bqu'on\b": "que on",
    r"\bqu'il\b": "que il",
    r"\bqu'elle\b": "que elle",
    r"\bqu'ils\b": "que ils",
    r"\bqu'elles\b": "que elles",
    r"\bjusqu'√†\b": "jusque √†",
    r"\bpr√®s d'ici\b": "pr√®s de ici",
    r"\bd'accord\b": "de accord",
}


def normaliser_contractions(texte):
    for contraction, forme_complete in contractions_fr.items():
        texte = re.sub(contraction, forme_complete, texte, flags=re.IGNORECASE)
    return texte


def nettoyer_texte(texte):
    texte = unicodedata.normalize('NFD', texte)  # Normalisation Unicode
    texte = ''.join(c for c in texte if unicodedata.category(c) != 'Mn')  # Supprime les accents
    texte = normaliser_contractions(texte)  # Normalise les contractions
    texte = re.sub(r'[^A-Za-z0-9\s\n]', '', texte)  # Supprime caract√®res sp√©ciaux, sauf les sauts de ligne (\n)
    return texte


def lire_stopwords(stopwords_path):
    doc = Document(stopwords_path)
    stopwords = []
    for para in doc.paragraphs:
        stopwords.extend(para.text.split())
    return stopwords


def supprimer_stopwords(texte, stopwords):
    lignes = texte.split('\n')  # S√©pare le texte en lignes
    lignes_filtrees = []
    for ligne in lignes:
        mots = ligne.split()
        mots_filtres = [mot for mot in mots if mot.lower() not in stopwords]
        ligne_filtree = ' '.join(mots_filtres)
        lignes_filtrees.append(ligne_filtree)
    return '\n'.join(lignes_filtrees)  # Rejoint les lignes avec des sauts de ligne


def traiter_fichier_word(input_path, output_path, stopwords_path):
    try:
        # V√©rifier si le fichier d'entr√©e existe
        if not os.path.exists(input_path):
            print(f"Erreur : Le fichier {input_path} n'existe pas.")
            return

        # Charger le fichier Word
        doc = Document(input_path)

        # Lire les stop words
        stopwords = lire_stopwords(stopwords_path)

        # Cr√©er un nouveau document pour stocker le texte trait√©
        nouveau_doc = Document()

        # Traiter chaque paragraphe du document original
        for para in doc.paragraphs:
            texte_original = para.text
            texte_nettoye = nettoyer_texte(texte_original)
            texte_filtre = supprimer_stopwords(texte_nettoye, stopwords)

            # Ajouter le texte filtr√© dans un nouveau paragraphe
            nouveau_doc.add_paragraph(texte_filtre)

        # Supprimer l'ancien fichier de sortie s'il existe
        if os.path.exists(output_path):
            os.remove(output_path)

        # Enregistrer le nouveau fichier Word
        nouveau_doc.save(output_path)
        print(f"‚úÖ Fichier enregistr√© sous : {output_path}")

    except PermissionError:
        print(f"‚ùå Erreur : Permission refus√©e pour √©crire dans {output_path}. \nüëâ Ferme Word et relance le script.")
    except Exception as e:
        print(f"‚ùå Une erreur est survenue : {e}")


# Exemple d'utilisation
input_file = "C:/Users/Awa Diop/Documents/E4 Eseo/projet de synth√®se/Retranscriptions_anonymes/A1_2023002752-3445953_2023-01-03_15-54-29_2023-01-03_15-55-57_Entrant.mp3.docx"
output_file = "C:/Users/Awa Diop/Documents/E4 Eseo/projet de synth√®se/preproccesing.docx"
stopwords_file = "C:/Users/Awa Diop/Documents/E4 Eseo/projet de synth√®se/stopwords.docx"  # Chemin vers le fichier stopwords.docx

traiter_fichier_word(input_file, output_file, stopwords_file)
